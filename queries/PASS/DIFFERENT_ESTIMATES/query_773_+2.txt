
============================STATS========================================
Actual Count: 0
Estimated Count: 2
Abs diff: 2
============================QUERY========================================
select  
  ref_0.c2 as c0, 
  ref_0.email as c1, 
  ref_0.id as c2
from 
  main.users as ref_0
where ref_0.email is NULL
============================OUTPUT========================================
[c0: string, c1: string ... 1 more field]
============================PLAN========================================
== Parsed Logical Plan ==
'Project ['ref_0.c2 AS c0#2670, 'ref_0.email AS c1#2671, 'ref_0.id AS c2#2672]
+- 'Filter isnull('ref_0.email)
   +- 'SubqueryAlias ref_0
      +- 'UnresolvedRelation [main, users]

== Analyzed Logical Plan ==
c0: string, c1: string, c2: int
Project [c2#1141 AS c0#2670, email#1142 AS c1#2671, id#1138 AS c2#2672]
+- Filter isnull(email#1142)
   +- SubqueryAlias ref_0
      +- SubqueryAlias spark_catalog.main.users
         +- Relation[c0#1137,id#1138,c1#1139,name#1140,c2#1141,email#1142] parquet

== Optimized Logical Plan ==
Project [c2#1141 AS c0#2670, email#1142 AS c1#2671, id#1138 AS c2#2672]
+- Filter isnull(email#1142)
   +- Relation[c0#1137,id#1138,c1#1139,name#1140,c2#1141,email#1142] parquet

== Physical Plan ==
*(1) Project [c2#1141 AS c0#2670, email#1142 AS c1#2671, id#1138 AS c2#2672]
+- *(1) Filter isnull(email#1142)
   +- *(1) ColumnarToRow
      +- FileScan parquet main.users[id#1138,c2#1141,email#1142] Batched: true, DataFilters: [isnull(email#1142)], Format: Parquet, Location: InMemoryFileIndex[file:/home/ahmad/Documents/project/cardinality-estimator-test/spark-warehouse/m..., PartitionFilters: [], PushedFilters: [IsNull(email)], ReadSchema: struct<id:int,c2:string,email:string>

