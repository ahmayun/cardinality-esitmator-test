
============================STATS========================================
Actual Count: 74
Estimated Count: 74
Abs diff: 0
============================QUERY========================================
select  
  ref_0.t_am_pm as c0
from 
  main.time_dim as ref_0
where 37 is not NULL
limit 74
============================OUTPUT========================================
[c0: string]
============================PLAN========================================
== Parsed Logical Plan ==
'GlobalLimit 74
+- 'LocalLimit 74
   +- 'Project ['ref_0.t_am_pm AS c0#4579]
      +- 'Filter isnotnull(37)
         +- 'SubqueryAlias ref_0
            +- 'UnresolvedRelation [main, time_dim]

== Analyzed Logical Plan ==
c0: string
GlobalLimit 74
+- LocalLimit 74
   +- Project [t_am_pm#1108 AS c0#4579]
      +- Filter isnotnull(37)
         +- SubqueryAlias ref_0
            +- SubqueryAlias spark_catalog.main.time_dim
               +- Relation[t_time_sk#1102,t_time_id#1103,t_time#1104,t_hour#1105,t_minute#1106,t_second#1107,t_am_pm#1108,t_shift#1109,t_sub_shift#1110,t_meal_time#1111] parquet

== Optimized Logical Plan ==
GlobalLimit 74
+- LocalLimit 74
   +- Project [t_am_pm#1108 AS c0#4579]
      +- Relation[t_time_sk#1102,t_time_id#1103,t_time#1104,t_hour#1105,t_minute#1106,t_second#1107,t_am_pm#1108,t_shift#1109,t_sub_shift#1110,t_meal_time#1111] parquet

== Physical Plan ==
CollectLimit 74
+- *(1) Project [t_am_pm#1108 AS c0#4579]
   +- *(1) ColumnarToRow
      +- FileScan parquet main.time_dim[t_am_pm#1108] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex[file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-ma..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_am_pm:string>

