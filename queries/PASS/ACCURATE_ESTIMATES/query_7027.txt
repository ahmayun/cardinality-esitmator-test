
============================STATS========================================
Actual Count: 103
Estimated Count: 103
Abs diff: 0
============================QUERY========================================
select  
  ref_0.d_day_name as c0, 
  case when ref_0.d_first_dom is not NULL then ref_0.d_dow else ref_0.d_dow end
     as c1
from 
  main.date_dim as ref_0
where ref_0.d_dom is not NULL
limit 103
============================OUTPUT========================================
[c0: string, c1: int]
============================PLAN========================================
== Parsed Logical Plan ==
'GlobalLimit 103
+- 'LocalLimit 103
   +- 'Project ['ref_0.d_day_name AS c0#6100, CASE WHEN isnotnull('ref_0.d_first_dom) THEN 'ref_0.d_dow ELSE 'ref_0.d_dow END AS c1#6101]
      +- 'Filter isnotnull('ref_0.d_dom)
         +- 'SubqueryAlias ref_0
            +- 'UnresolvedRelation [main, date_dim]

== Analyzed Logical Plan ==
c0: string, c1: int
GlobalLimit 103
+- LocalLimit 103
   +- Project [d_day_name#546 AS c0#6100, CASE WHEN isnotnull(d_first_dom#551) THEN d_dow#539 ELSE d_dow#539 END AS c1#6101]
      +- Filter isnotnull(d_dom#541)
         +- SubqueryAlias ref_0
            +- SubqueryAlias spark_catalog.main.date_dim
               +- Relation[d_date_sk#532,d_date_id#533,d_date#534,d_month_seq#535,d_week_seq#536,d_quarter_seq#537,d_year#538,d_dow#539,d_moy#540,d_dom#541,d_qoy#542,d_fy_year#543,d_fy_quarter_seq#544,d_fy_week_seq#545,d_day_name#546,d_quarter_name#547,d_holiday#548,d_weekend#549,d_following_holiday#550,d_first_dom#551,d_last_dom#552,d_same_day_ly#553,d_same_day_lq#554,d_current_day#555,... 4 more fields] parquet

== Optimized Logical Plan ==
GlobalLimit 103
+- LocalLimit 103
   +- Project [d_day_name#546 AS c0#6100, d_dow#539 AS c1#6101]
      +- Filter isnotnull(d_dom#541)
         +- Relation[d_date_sk#532,d_date_id#533,d_date#534,d_month_seq#535,d_week_seq#536,d_quarter_seq#537,d_year#538,d_dow#539,d_moy#540,d_dom#541,d_qoy#542,d_fy_year#543,d_fy_quarter_seq#544,d_fy_week_seq#545,d_day_name#546,d_quarter_name#547,d_holiday#548,d_weekend#549,d_following_holiday#550,d_first_dom#551,d_last_dom#552,d_same_day_ly#553,d_same_day_lq#554,d_current_day#555,... 4 more fields] parquet

== Physical Plan ==
CollectLimit 103
+- *(1) Project [d_day_name#546 AS c0#6100, d_dow#539 AS c1#6101]
   +- *(1) Filter isnotnull(d_dom#541)
      +- *(1) ColumnarToRow
         +- FileScan parquet main.date_dim[d_dow#539,d_dom#541,d_day_name#546] Batched: true, DataFilters: [isnotnull(d_dom#541)], Format: Parquet, Location: InMemoryFileIndex[file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-ma..., PartitionFilters: [], PushedFilters: [IsNotNull(d_dom)], ReadSchema: struct<d_dow:int,d_dom:int,d_day_name:string>

