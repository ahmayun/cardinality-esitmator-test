
============================STATS========================================
Actual Count: 73049
Estimated Count: 73049
Abs diff: 0
============================QUERY========================================
select  
  ref_0.d_same_day_ly as c0, 
  ref_0.d_following_holiday as c1
from 
  main.date_dim as ref_0
where ref_0.d_qoy is not NULL
============================OUTPUT========================================
[c0: int, c1: string]
============================PLAN========================================
== Parsed Logical Plan ==
'Project ['ref_0.d_same_day_ly AS c0#6914, 'ref_0.d_following_holiday AS c1#6915]
+- 'Filter isnotnull('ref_0.d_qoy)
   +- 'SubqueryAlias ref_0
      +- 'UnresolvedRelation [main, date_dim]

== Analyzed Logical Plan ==
c0: int, c1: string
Project [d_same_day_ly#553 AS c0#6914, d_following_holiday#550 AS c1#6915]
+- Filter isnotnull(d_qoy#542)
   +- SubqueryAlias ref_0
      +- SubqueryAlias spark_catalog.main.date_dim
         +- Relation[d_date_sk#532,d_date_id#533,d_date#534,d_month_seq#535,d_week_seq#536,d_quarter_seq#537,d_year#538,d_dow#539,d_moy#540,d_dom#541,d_qoy#542,d_fy_year#543,d_fy_quarter_seq#544,d_fy_week_seq#545,d_day_name#546,d_quarter_name#547,d_holiday#548,d_weekend#549,d_following_holiday#550,d_first_dom#551,d_last_dom#552,d_same_day_ly#553,d_same_day_lq#554,d_current_day#555,... 4 more fields] parquet

== Optimized Logical Plan ==
Project [d_same_day_ly#553 AS c0#6914, d_following_holiday#550 AS c1#6915]
+- Filter isnotnull(d_qoy#542)
   +- Relation[d_date_sk#532,d_date_id#533,d_date#534,d_month_seq#535,d_week_seq#536,d_quarter_seq#537,d_year#538,d_dow#539,d_moy#540,d_dom#541,d_qoy#542,d_fy_year#543,d_fy_quarter_seq#544,d_fy_week_seq#545,d_day_name#546,d_quarter_name#547,d_holiday#548,d_weekend#549,d_following_holiday#550,d_first_dom#551,d_last_dom#552,d_same_day_ly#553,d_same_day_lq#554,d_current_day#555,... 4 more fields] parquet

== Physical Plan ==
*(1) Project [d_same_day_ly#553 AS c0#6914, d_following_holiday#550 AS c1#6915]
+- *(1) Filter isnotnull(d_qoy#542)
   +- *(1) ColumnarToRow
      +- FileScan parquet main.date_dim[d_qoy#542,d_following_holiday#550,d_same_day_ly#553] Batched: true, DataFilters: [isnotnull(d_qoy#542)], Format: Parquet, Location: InMemoryFileIndex[file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-ma..., PartitionFilters: [], PushedFilters: [IsNotNull(d_qoy)], ReadSchema: struct<d_qoy:int,d_following_holiday:string,d_same_day_ly:int>

