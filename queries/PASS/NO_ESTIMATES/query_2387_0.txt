
============================STATS========================================
Actual Count: 0
Estimated Count: No Estimate
Abs diff: 1
============================QUERY========================================
insert into main.inventory values (
27, 
78, 
15, 
18)
============================OUTPUT========================================
[]
============================PLAN========================================
== Parsed Logical Plan ==
'InsertIntoStatement 'UnresolvedRelation [main, inventory], false, false
+- 'UnresolvedInlineTable [col1, col2, col3, col4], [List(27, 78, 15, 18)]

== Analyzed Logical Plan ==

InsertIntoHadoopFsRelationCommand file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory, false, [inv_date_sk#3558], Parquet, Map(path -> file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory), Append, CatalogTable(
Database: main
Table: inventory
Owner: ahmad
Created Time: Fri Nov 01 22:19:23 EDT 2024
Last Access: UNKNOWN
Created By: Spark 3.0.0
Type: EXTERNAL
Provider: parquet
Statistics: 46354214 bytes
Location: file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory
Serde Library: org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe
InputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat
OutputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat
Partition Provider: Catalog
Partition Columns: [`inv_date_sk`]
Schema: root
-- inv_item_sk: integer (nullable = true)
-- inv_warehouse_sk: integer (nullable = true)
-- inv_quantity_on_hand: integer (nullable = true)
-- inv_date_sk: integer (nullable = true)
), org.apache.spark.sql.execution.datasources.CatalogFileIndex@4f4d72a5, [inv_item_sk, inv_warehouse_sk, inv_quantity_on_hand, inv_date_sk]
+- Project [ansi_cast(col1#3547 as int) AS inv_item_sk#3555, ansi_cast(col2#3548 as int) AS inv_warehouse_sk#3556, ansi_cast(col3#3549 as int) AS inv_quantity_on_hand#3557, ansi_cast(col4#3550 as int) AS inv_date_sk#3558]
   +- LocalRelation [col1#3547, col2#3548, col3#3549, col4#3550]

== Optimized Logical Plan ==
InsertIntoHadoopFsRelationCommand file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory, false, [inv_date_sk#3558], Parquet, Map(path -> file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory), Append, CatalogTable(
Database: main
Table: inventory
Owner: ahmad
Created Time: Fri Nov 01 22:19:23 EDT 2024
Last Access: UNKNOWN
Created By: Spark 3.0.0
Type: EXTERNAL
Provider: parquet
Statistics: 46354214 bytes
Location: file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory
Serde Library: org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe
InputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat
OutputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat
Partition Provider: Catalog
Partition Columns: [`inv_date_sk`]
Schema: root
-- inv_item_sk: integer (nullable = true)
-- inv_warehouse_sk: integer (nullable = true)
-- inv_quantity_on_hand: integer (nullable = true)
-- inv_date_sk: integer (nullable = true)
), org.apache.spark.sql.execution.datasources.CatalogFileIndex@4f4d72a5, [inv_item_sk, inv_warehouse_sk, inv_quantity_on_hand, inv_date_sk]
+- LocalRelation [inv_item_sk#3555, inv_warehouse_sk#3556, inv_quantity_on_hand#3557, inv_date_sk#3558]

== Physical Plan ==
Execute InsertIntoHadoopFsRelationCommand file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory, false, [inv_date_sk#3558], Parquet, Map(path -> file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory), Append, CatalogTable(
Database: main
Table: inventory
Owner: ahmad
Created Time: Fri Nov 01 22:19:23 EDT 2024
Last Access: UNKNOWN
Created By: Spark 3.0.0
Type: EXTERNAL
Provider: parquet
Statistics: 46354214 bytes
Location: file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory
Serde Library: org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe
InputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat
OutputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat
Partition Provider: Catalog
Partition Columns: [`inv_date_sk`]
Schema: root
-- inv_item_sk: integer (nullable = true)
-- inv_warehouse_sk: integer (nullable = true)
-- inv_quantity_on_hand: integer (nullable = true)
-- inv_date_sk: integer (nullable = true)
), org.apache.spark.sql.execution.datasources.CatalogFileIndex@4f4d72a5, [inv_item_sk, inv_warehouse_sk, inv_quantity_on_hand, inv_date_sk]
+- LocalTableScan [inv_item_sk#3555, inv_warehouse_sk#3556, inv_quantity_on_hand#3557, inv_date_sk#3558]

