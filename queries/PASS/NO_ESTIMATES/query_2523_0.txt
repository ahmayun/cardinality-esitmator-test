
============================STATS========================================
Actual Count: 0
Estimated Count: No Estimate
Abs diff: 1
============================QUERY========================================
insert into main.inventory values (
67, 
60, 
96, 
80)
============================OUTPUT========================================
[]
============================PLAN========================================
== Parsed Logical Plan ==
'InsertIntoStatement 'UnresolvedRelation [main, inventory], false, false
+- 'UnresolvedInlineTable [col1, col2, col3, col4], [List(67, 60, 96, 80)]

== Analyzed Logical Plan ==

InsertIntoHadoopFsRelationCommand file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory, false, [inv_date_sk#3602], Parquet, Map(path -> file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory), Append, CatalogTable(
Database: main
Table: inventory
Owner: ahmad
Created Time: Fri Nov 01 22:19:23 EDT 2024
Last Access: UNKNOWN
Created By: Spark 3.0.0
Type: EXTERNAL
Provider: parquet
Statistics: 46356062 bytes
Location: file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory
Serde Library: org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe
InputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat
OutputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat
Partition Provider: Catalog
Partition Columns: [`inv_date_sk`]
Schema: root
-- inv_item_sk: integer (nullable = true)
-- inv_warehouse_sk: integer (nullable = true)
-- inv_quantity_on_hand: integer (nullable = true)
-- inv_date_sk: integer (nullable = true)
), org.apache.spark.sql.execution.datasources.CatalogFileIndex@4f4d72a5, [inv_item_sk, inv_warehouse_sk, inv_quantity_on_hand, inv_date_sk]
+- Project [ansi_cast(col1#3591 as int) AS inv_item_sk#3599, ansi_cast(col2#3592 as int) AS inv_warehouse_sk#3600, ansi_cast(col3#3593 as int) AS inv_quantity_on_hand#3601, ansi_cast(col4#3594 as int) AS inv_date_sk#3602]
   +- LocalRelation [col1#3591, col2#3592, col3#3593, col4#3594]

== Optimized Logical Plan ==
InsertIntoHadoopFsRelationCommand file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory, false, [inv_date_sk#3602], Parquet, Map(path -> file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory), Append, CatalogTable(
Database: main
Table: inventory
Owner: ahmad
Created Time: Fri Nov 01 22:19:23 EDT 2024
Last Access: UNKNOWN
Created By: Spark 3.0.0
Type: EXTERNAL
Provider: parquet
Statistics: 46356062 bytes
Location: file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory
Serde Library: org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe
InputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat
OutputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat
Partition Provider: Catalog
Partition Columns: [`inv_date_sk`]
Schema: root
-- inv_item_sk: integer (nullable = true)
-- inv_warehouse_sk: integer (nullable = true)
-- inv_quantity_on_hand: integer (nullable = true)
-- inv_date_sk: integer (nullable = true)
), org.apache.spark.sql.execution.datasources.CatalogFileIndex@4f4d72a5, [inv_item_sk, inv_warehouse_sk, inv_quantity_on_hand, inv_date_sk]
+- LocalRelation [inv_item_sk#3599, inv_warehouse_sk#3600, inv_quantity_on_hand#3601, inv_date_sk#3602]

== Physical Plan ==
Execute InsertIntoHadoopFsRelationCommand file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory, false, [inv_date_sk#3602], Parquet, Map(path -> file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory), Append, CatalogTable(
Database: main
Table: inventory
Owner: ahmad
Created Time: Fri Nov 01 22:19:23 EDT 2024
Last Access: UNKNOWN
Created By: Spark 3.0.0
Type: EXTERNAL
Provider: parquet
Statistics: 46356062 bytes
Location: file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory
Serde Library: org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe
InputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat
OutputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat
Partition Provider: Catalog
Partition Columns: [`inv_date_sk`]
Schema: root
-- inv_item_sk: integer (nullable = true)
-- inv_warehouse_sk: integer (nullable = true)
-- inv_quantity_on_hand: integer (nullable = true)
-- inv_date_sk: integer (nullable = true)
), org.apache.spark.sql.execution.datasources.CatalogFileIndex@4f4d72a5, [inv_item_sk, inv_warehouse_sk, inv_quantity_on_hand, inv_date_sk]
+- LocalTableScan [inv_item_sk#3599, inv_warehouse_sk#3600, inv_quantity_on_hand#3601, inv_date_sk#3602]

