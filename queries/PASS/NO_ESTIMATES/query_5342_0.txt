
============================STATS========================================
Actual Count: 0
Estimated Count: No Estimate
Abs diff: 1
============================QUERY========================================
select  
  ref_0.inv_warehouse_sk as c0, 
  case when ref_0.inv_warehouse_sk is not NULL then ref_0.inv_warehouse_sk else ref_0.inv_warehouse_sk end
     as c1, 
  ref_0.inv_item_sk as c2, 
  ref_0.inv_date_sk as c3
from 
  main.inventory as ref_0
where ref_0.inv_warehouse_sk is NULL
============================OUTPUT========================================
[c0: int, c1: int ... 2 more fields]
============================PLAN========================================
== Parsed Logical Plan ==
'Project ['ref_0.inv_warehouse_sk AS c0#5136, CASE WHEN isnotnull('ref_0.inv_warehouse_sk) THEN 'ref_0.inv_warehouse_sk ELSE 'ref_0.inv_warehouse_sk END AS c1#5137, 'ref_0.inv_item_sk AS c2#5138, 'ref_0.inv_date_sk AS c3#5139]
+- 'Filter isnull('ref_0.inv_warehouse_sk)
   +- 'SubqueryAlias ref_0
      +- 'UnresolvedRelation [main, inventory]

== Analyzed Logical Plan ==
c0: int, c1: int, c2: int, c3: int
Project [inv_warehouse_sk#4745 AS c0#5136, CASE WHEN isnotnull(inv_warehouse_sk#4745) THEN inv_warehouse_sk#4745 ELSE inv_warehouse_sk#4745 END AS c1#5137, inv_item_sk#4744 AS c2#5138, inv_date_sk#4747 AS c3#5139]
+- Filter isnull(inv_warehouse_sk#4745)
   +- SubqueryAlias ref_0
      +- SubqueryAlias spark_catalog.main.inventory
         +- Relation[inv_item_sk#4744,inv_warehouse_sk#4745,inv_quantity_on_hand#4746,inv_date_sk#4747] parquet

== Optimized Logical Plan ==
Project [inv_warehouse_sk#4745 AS c0#5136, inv_warehouse_sk#4745 AS c1#5137, inv_item_sk#4744 AS c2#5138, inv_date_sk#4747 AS c3#5139]
+- Filter isnull(inv_warehouse_sk#4745)
   +- Relation[inv_item_sk#4744,inv_warehouse_sk#4745,inv_quantity_on_hand#4746,inv_date_sk#4747] parquet

== Physical Plan ==
*(1) Project [inv_warehouse_sk#4745 AS c0#5136, inv_warehouse_sk#4745 AS c1#5137, inv_item_sk#4744 AS c2#5138, inv_date_sk#4747 AS c3#5139]
+- *(1) Filter isnull(inv_warehouse_sk#4745)
   +- *(1) ColumnarToRow
      +- FileScan parquet main.inventory[inv_item_sk#4744,inv_warehouse_sk#4745,inv_date_sk#4747] Batched: true, DataFilters: [isnull(inv_warehouse_sk#4745)], Format: Parquet, Location: CatalogFileIndex[file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-mai..., PartitionFilters: [], PushedFilters: [IsNull(inv_warehouse_sk)], ReadSchema: struct<inv_item_sk:int,inv_warehouse_sk:int>

