
============================STATS========================================
Actual Count: 0
Estimated Count: 62
Abs diff: 62
============================QUERY========================================
select  
  ref_0.d_date_id as c0, 
  ref_0.d_current_week as c1, 
  ref_0.d_current_month as c2
from 
  main.date_dim as ref_0
where ref_0.d_same_day_ly is NULL
limit 62
============================OUTPUT========================================
[c0: string, c1: string ... 1 more field]
============================PLAN========================================
== Parsed Logical Plan ==
'GlobalLimit 62
+- 'LocalLimit 62
   +- 'Project ['ref_0.d_date_id AS c0#5084, 'ref_0.d_current_week AS c1#5085, 'ref_0.d_current_month AS c2#5086]
      +- 'Filter isnull('ref_0.d_same_day_ly)
         +- 'SubqueryAlias ref_0
            +- 'UnresolvedRelation [main, date_dim]

== Analyzed Logical Plan ==
c0: string, c1: string, c2: string
GlobalLimit 62
+- LocalLimit 62
   +- Project [d_date_id#533 AS c0#5084, d_current_week#556 AS c1#5085, d_current_month#557 AS c2#5086]
      +- Filter isnull(d_same_day_ly#553)
         +- SubqueryAlias ref_0
            +- SubqueryAlias spark_catalog.main.date_dim
               +- Relation[d_date_sk#532,d_date_id#533,d_date#534,d_month_seq#535,d_week_seq#536,d_quarter_seq#537,d_year#538,d_dow#539,d_moy#540,d_dom#541,d_qoy#542,d_fy_year#543,d_fy_quarter_seq#544,d_fy_week_seq#545,d_day_name#546,d_quarter_name#547,d_holiday#548,d_weekend#549,d_following_holiday#550,d_first_dom#551,d_last_dom#552,d_same_day_ly#553,d_same_day_lq#554,d_current_day#555,... 4 more fields] parquet

== Optimized Logical Plan ==
GlobalLimit 62
+- LocalLimit 62
   +- Project [d_date_id#533 AS c0#5084, d_current_week#556 AS c1#5085, d_current_month#557 AS c2#5086]
      +- Filter isnull(d_same_day_ly#553)
         +- Relation[d_date_sk#532,d_date_id#533,d_date#534,d_month_seq#535,d_week_seq#536,d_quarter_seq#537,d_year#538,d_dow#539,d_moy#540,d_dom#541,d_qoy#542,d_fy_year#543,d_fy_quarter_seq#544,d_fy_week_seq#545,d_day_name#546,d_quarter_name#547,d_holiday#548,d_weekend#549,d_following_holiday#550,d_first_dom#551,d_last_dom#552,d_same_day_ly#553,d_same_day_lq#554,d_current_day#555,... 4 more fields] parquet

== Physical Plan ==
CollectLimit 62
+- *(1) Project [d_date_id#533 AS c0#5084, d_current_week#556 AS c1#5085, d_current_month#557 AS c2#5086]
   +- *(1) Filter isnull(d_same_day_ly#553)
      +- *(1) ColumnarToRow
         +- FileScan parquet main.date_dim[d_date_id#533,d_same_day_ly#553,d_current_week#556,d_current_month#557] Batched: true, DataFilters: [isnull(d_same_day_ly#553)], Format: Parquet, Location: InMemoryFileIndex[file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-ma..., PartitionFilters: [], PushedFilters: [IsNull(d_same_day_ly)], ReadSchema: struct<d_date_id:string,d_same_day_ly:int,d_current_week:string,d_current_month:string>

