
============================STATS========================================
Actual Count: 0
Estimated Count: No Estimate
Abs diff: 1
============================QUERY========================================
insert into main.inventory values (
97, 
37, 
44, 
44)
============================OUTPUT========================================
[]
============================PLAN========================================
== Parsed Logical Plan ==
'InsertIntoStatement 'UnresolvedRelation [main, inventory], false, false
+- 'UnresolvedInlineTable [col1, col2, col3, col4], [List(97, 37, 44, 44)]

== Analyzed Logical Plan ==

InsertIntoHadoopFsRelationCommand file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory, false, [inv_date_sk#2148], Parquet, Map(path -> file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory), Append, CatalogTable(
Database: main
Table: inventory
Owner: ahmad
Created Time: Fri Nov 01 22:19:23 EDT 2024
Last Access: UNKNOWN
Created By: Spark 3.0.0
Type: EXTERNAL
Provider: parquet
Statistics: 46352366 bytes
Location: file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory
Serde Library: org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe
InputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat
OutputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat
Partition Provider: Catalog
Partition Columns: [`inv_date_sk`]
Schema: root
-- inv_item_sk: integer (nullable = true)
-- inv_warehouse_sk: integer (nullable = true)
-- inv_quantity_on_hand: integer (nullable = true)
-- inv_date_sk: integer (nullable = true)
), org.apache.spark.sql.execution.datasources.CatalogFileIndex@4f4d72a5, [inv_item_sk, inv_warehouse_sk, inv_quantity_on_hand, inv_date_sk]
+- Project [ansi_cast(col1#2137 as int) AS inv_item_sk#2145, ansi_cast(col2#2138 as int) AS inv_warehouse_sk#2146, ansi_cast(col3#2139 as int) AS inv_quantity_on_hand#2147, ansi_cast(col4#2140 as int) AS inv_date_sk#2148]
   +- LocalRelation [col1#2137, col2#2138, col3#2139, col4#2140]

== Optimized Logical Plan ==
InsertIntoHadoopFsRelationCommand file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory, false, [inv_date_sk#2148], Parquet, Map(path -> file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory), Append, CatalogTable(
Database: main
Table: inventory
Owner: ahmad
Created Time: Fri Nov 01 22:19:23 EDT 2024
Last Access: UNKNOWN
Created By: Spark 3.0.0
Type: EXTERNAL
Provider: parquet
Statistics: 46352366 bytes
Location: file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory
Serde Library: org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe
InputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat
OutputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat
Partition Provider: Catalog
Partition Columns: [`inv_date_sk`]
Schema: root
-- inv_item_sk: integer (nullable = true)
-- inv_warehouse_sk: integer (nullable = true)
-- inv_quantity_on_hand: integer (nullable = true)
-- inv_date_sk: integer (nullable = true)
), org.apache.spark.sql.execution.datasources.CatalogFileIndex@4f4d72a5, [inv_item_sk, inv_warehouse_sk, inv_quantity_on_hand, inv_date_sk]
+- LocalRelation [inv_item_sk#2145, inv_warehouse_sk#2146, inv_quantity_on_hand#2147, inv_date_sk#2148]

== Physical Plan ==
Execute InsertIntoHadoopFsRelationCommand file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory, false, [inv_date_sk#2148], Parquet, Map(path -> file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory), Append, CatalogTable(
Database: main
Table: inventory
Owner: ahmad
Created Time: Fri Nov 01 22:19:23 EDT 2024
Last Access: UNKNOWN
Created By: Spark 3.0.0
Type: EXTERNAL
Provider: parquet
Statistics: 46352366 bytes
Location: file:/home/ahmad/Documents/project/cardinality-estimator-test/tpcds-data-for-main/inventory
Serde Library: org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe
InputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat
OutputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat
Partition Provider: Catalog
Partition Columns: [`inv_date_sk`]
Schema: root
-- inv_item_sk: integer (nullable = true)
-- inv_warehouse_sk: integer (nullable = true)
-- inv_quantity_on_hand: integer (nullable = true)
-- inv_date_sk: integer (nullable = true)
), org.apache.spark.sql.execution.datasources.CatalogFileIndex@4f4d72a5, [inv_item_sk, inv_warehouse_sk, inv_quantity_on_hand, inv_date_sk]
+- LocalTableScan [inv_item_sk#2145, inv_warehouse_sk#2146, inv_quantity_on_hand#2147, inv_date_sk#2148]

