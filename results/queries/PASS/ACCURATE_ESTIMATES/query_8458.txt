
============================STATS========================================
Actual Count: 2
Estimated Count: 2
Abs diff: 0
============================QUERY========================================
select  
  case when ref_0.id is not NULL then ref_0.email else ref_0.email end
     as c0
from 
  main.users as ref_0
where (ref_0.c2 is NULL) 
  or (ref_0.c0 is not NULL)
limit 122
============================OUTPUT========================================
[c0: string]
============================PLAN========================================
== Parsed Logical Plan ==
'GlobalLimit 122
+- 'LocalLimit 122
   +- 'Project [CASE WHEN isnotnull('ref_0.id) THEN 'ref_0.email ELSE 'ref_0.email END AS c0#6680]
      +- 'Filter (isnull('ref_0.c2) OR isnotnull('ref_0.c0))
         +- 'SubqueryAlias ref_0
            +- 'UnresolvedRelation [main, users]

== Analyzed Logical Plan ==
c0: string
GlobalLimit 122
+- LocalLimit 122
   +- Project [CASE WHEN isnotnull(id#1138) THEN email#1142 ELSE email#1142 END AS c0#6680]
      +- Filter (isnull(c2#1141) OR isnotnull(c0#1137))
         +- SubqueryAlias ref_0
            +- SubqueryAlias spark_catalog.main.users
               +- Relation[c0#1137,id#1138,c1#1139,name#1140,c2#1141,email#1142] parquet

== Optimized Logical Plan ==
GlobalLimit 122
+- LocalLimit 122
   +- Project [email#1142 AS c0#6680]
      +- Filter (isnull(c2#1141) OR isnotnull(c0#1137))
         +- Relation[c0#1137,id#1138,c1#1139,name#1140,c2#1141,email#1142] parquet

== Physical Plan ==
CollectLimit 122
+- *(1) Project [email#1142 AS c0#6680]
   +- *(1) Filter (isnull(c2#1141) OR isnotnull(c0#1137))
      +- *(1) ColumnarToRow
         +- FileScan parquet main.users[c0#1137,c2#1141,email#1142] Batched: true, DataFilters: [(isnull(c2#1141) OR isnotnull(c0#1137))], Format: Parquet, Location: InMemoryFileIndex[file:/home/ahmad/Documents/project/cardinality-estimator-test/spark-warehouse/m..., PartitionFilters: [], PushedFilters: [Or(IsNull(c2),IsNotNull(c0))], ReadSchema: struct<c0:int,c2:string,email:string>

